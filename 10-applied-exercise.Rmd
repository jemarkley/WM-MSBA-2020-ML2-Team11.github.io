---
title: "Ch10 Applied Exercise"
---
In this problem, you will generate simulated data, and then perform PCA and K-means clustering on the data.

(a)	Generate a simulated data set with 20 observations in each of three classes (i.e. 60 observations total), and 50 variables. 

```{r}
set.seed(2)
x <- matrix(rnorm(20 * 3 * 50, mean = 0, sd = 0.001), ncol = 50)
x[1:20, 2] <- 1
x[21:40, 1] <- 2
x[21:40, 2] <- 2
x[41:60, 1] <- 1
true.labels <- c(rep(1, 20), rep(2, 20), rep(3, 20))
```

(b) Perform PCA on the 60 observations and plot the first two principal component score vectors. Use a different color to indicate the observations in each of the three classes.

```{r}
pcr.out <- prcomp(x)
plot(pcr.out$x[,1:2], col = 1:3, xlab = 'Z1', ylab = 'Z2', main = 'First Two Principal Component', pch = 19)
```

(c) Perform K-means clustering of the observations with K = 3. How well do the clusters that you obtained in K-means clustering compare to the true class labels? 

```{r}
km.out <- kmeans(x, 3, nstart = 20)
table(true.labels, km.out$cluster)
```
##### *The observations are perfectly clustered.*

(d) Perform K-means clustering with K = 2. Describe your results.

```{r}
km.out <- kmeans(x, 2, nstart = 20)
table(true.labels, km.out$cluster)
```
##### *All observations of one of the three clusters is now absorbed in one of the two clusters. *

(e) Now perform K-means clustering with K = 4, and describe your results. 

```{r}
km.out <- kmeans(x, 4, nstart = 20)
table(true.labels, km.out$cluster)
```
##### *The first cluster is splitted into two clusters.*

(f) Now perform K-means clustering with K = 3 on the first two principal component score vectors, rather than on the raw data. That is, perform K-means clustering on the 60 Ã— 2 matrix of which the first column is the first principal component score vector, and the second column is the second principal component score vector. Comment on the results. 

```{r}
km.out <- kmeans(pcr.out$x[,1:2], 3, nstart = 20)
table(true.labels, km.out$cluster)
```
##### *The observations are 56 out of 60 correctly matched with true class labels; there are 4 observations are clustered with wrong labels.*

(g) Using the scale() function, perform K-means clustering with K = 3 on the data after scaling each variable to have standard deviation one. How do these results compare to those obtained in (b)? 

```{r}
km.out <- kmeans(scale(x), 3, nstart = 20)
table(true.labels, km.out$cluster)
```
##### *We may see that we have worse results than with unscaled data, as scaling affects the distance between the observations.*